## 1. Базовые операции с векторами

### 1.1 Нормы векторов (L1, L2)
$$
\begin{cases}
2x + y - z = 8 \\
-3x - y + 2z = -11 \\
-2x + y + 2z = -3
\end{cases}
$$

**Задача 1 — Нормализация признаков**  
**Вводные данные:**  
Вектор признаков объекта

x=[120,80,200,50]

**Задача:**

1. Реализовать функции вычисления L1 и L2 норм.
    
2. Нормализовать вектор по L1 и по L2.
    
3. Сравнить, как меняется вклад каждого признака после нормализации.
    

**Что найти:**

- L1(x), L2(x)
    
- нормализованные векторы
    
- интерпретацию разницы (устойчивость к выбросам)
    

---

### 1.2 Скалярное произведение

**Задача 2 — Взвешенная сумма признаков**  
**Вводные данные:**  
Вектор признаков объекта

x=[2,3,5]

Вектор весов модели

w=[0.4,0.1,0.5]

**Задача:**

1. Реализовать скалярное произведение без `np.dot`.
    
2. Посчитать выход линейной модели.
    

**Что найти:**

- значение скалярного произведения
    
- вклад каждого признака в итоговый результат
    

---

### 1.3 Косинусная близость

**Задача 3 — Сравнение объектов по направлению**  
**Вводные данные:**  
Три вектора пользователей:

u1=[5,0,1]
u2=[4,1,0]
u3=[0,3,5]

**Задача:**

1. Реализовать косинусную близость.
    
2. Найти, кто ближе всего к u1u_1u1​.
    

**Что найти:**

- cos(u₁, u₂), cos(u₁, u₃)
    
- вывод о сходстве независимо от масштаба
    

---

### 1.4 Проекции векторов

**Задача 4 — Проекция признаков на направление**  
**Вводные данные:**  
Вектор данных

x=[3,4]

Вектор направления

v=[1,1]

**Задача:**

1. Реализовать формулу проекции.
    
2. Найти проекцию xxx на vvv.
    
3. Найти ортогональную компоненту.
    

**Что найти:**

- вектор проекции
    
- остаток (ошибка аппроксимации)
    

---

## 2. Матричные операции

### 2.1 Умножение, транспонирование, обратная матрица

**Задача 5 — Линейное преобразование данных**  
**Вводные данные:**  
Матрица данных

X = [1 2] 
    [3 4] 
    [5 6]​​

Матрица преобразования

W = [20]
    [01]

**Задача:**

1. Реализовать матричное умножение вручную.
    
2. Применить линейное преобразование XWXWXW.
    
3. Реализовать транспонирование.
    

**Что найти:**

- результат преобразования
    
- смысл операции как масштабирования признаков
    

---

### 2.2 Детерминант, ранг, линейная независимость

**Задача 6 — Проверка вырожденности данных**  
**Вводные данные:**  
Матрицы:

A=[12]
  [24],
B=[12]
  [34]

**Задача:**

1. Реализовать детерминант (2×2 и 3×3).
    
2. Определить ранг матриц.
    
3. Проверить линейную независимость столбцов.
    

**Что найти:**

- det(A), det(B)
    
- rank(A), rank(B)
    
- вывод о коллинеарности признаков
    

---

## 3. Решение линейных систем

### 3.1 Метод Гаусса

**Задача 7 — Решение системы уравнений**  
**Вводные данные:**

{2x+y−z=8
{−3x−y+2z=−11
{−2x+y+2z=−3​

**Задача:**

1. Реализовать прямой и обратный ход метода Гаусса.
    
2. Найти решение системы.
    

**Что найти:**

- значения x,y,zx, y, zx,y,z
    
- проверить решение подстановкой
    

---

### 3.2 LU-разложение

**Задача 8 — Повторное решение систем**  
**Вводные данные:**  
Матрица коэффициентов

A=[43]
  [63

Два вектора правой части:

b1=[10,12],
b2=[8,10]

**Задача:**

1. Реализовать LU-разложение без библиотек.
    
2. Решить обе системы через L и U.
    

**Что найти:**

- матрицы L и U
    
- решения для b1b_1b1​ и b2b_2b2​
    
- объяснение, почему LU выгодно при множественных b
